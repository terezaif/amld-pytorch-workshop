{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-Modules.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/terezaif/amld-pytorch-workshop/blob/master/4-Modules.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "kudfvBry4KSs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PyTorch Modules"
      ]
    },
    {
      "metadata": {
        "id": "zJPvPcSm4KSu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### What is this notebook about?\n",
        "\n",
        "In this notebook, we will learning about PyTorch modules and the great functionalities they provide. Later on, we'll create a small a multilayer perceptron to perform image classification on MNIST."
      ]
    },
    {
      "metadata": {
        "id": "QKdWXiOm4KSw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "___"
      ]
    },
    {
      "metadata": {
        "id": "VRYBOHi84KSx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Google Colab only!"
      ]
    },
    {
      "metadata": {
        "id": "9FxxcLHq4KSz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# execute only if you're using Google Colab\n",
        "!wget -q https://raw.githubusercontent.com/ahug/amld-pytorch-workshop/master/binder/requirements.txt -O requirements.txt\n",
        "!pip install -qr requirements.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XfPMlP574KS2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "____"
      ]
    },
    {
      "metadata": {
        "id": "6wWdygpJ4KS3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "b3258d28-81a3-4ae4-9a4d-caa9d6f121df"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version: 1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zpULRP4e4KS5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FnSlCyQL4KS8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In PyTorch, there are many predefined layer like Convolutions, RNN, Pooling, Linear, etc.\n",
        "\n",
        "These functions are wrapped in **modules** and inherit from the **torch.nn.Module** base class.\n",
        "\n",
        "When designing a custom model in PyTorch, you should follow this strategy and derive your class from **torch.nn.Module**."
      ]
    },
    {
      "metadata": {
        "id": "joJpucoH4KS9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modules"
      ]
    },
    {
      "metadata": {
        "id": "h9mfEAoQ4KS-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "a44dab9c-b495-4428-8907-d936b5961799"
      },
      "cell_type": "code",
      "source": [
        "print(torch.nn.Module.__doc__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base class for all neural network modules.\n",
            "\n",
            "    Your models should also subclass this class.\n",
            "\n",
            "    Modules can also contain other Modules, allowing to nest them in\n",
            "    a tree structure. You can assign the submodules as regular attributes::\n",
            "\n",
            "        import torch.nn as nn\n",
            "        import torch.nn.functional as F\n",
            "\n",
            "        class Model(nn.Module):\n",
            "            def __init__(self):\n",
            "                super(Model, self).__init__()\n",
            "                self.conv1 = nn.Conv2d(1, 20, 5)\n",
            "                self.conv2 = nn.Conv2d(20, 20, 5)\n",
            "\n",
            "            def forward(self, x):\n",
            "               x = F.relu(self.conv1(x))\n",
            "               return F.relu(self.conv2(x))\n",
            "\n",
            "    Submodules assigned in this way will be registered, and will have their\n",
            "    parameters converted too when you call :meth:`to`, etc.\n",
            "    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eAjX-GAI4KTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Modules are doing a lot of \"magic\" under the hood.\n",
        "\n",
        "- It registers all the parameters of your model.\n",
        "- It simplifies the saving/loading of your model.\n",
        "- It provides helper functions to reset/freeze/update the gradients.\n",
        "- It provides helper functions to put all parameters on a device (GPU)."
      ]
    },
    {
      "metadata": {
        "id": "m-aLiC8o4KTB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### What is a torch.nn.Parameter?"
      ]
    },
    {
      "metadata": {
        "id": "sfW1w5pn4KTC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A Parameter is a Tensor with `requires_grad` to `True` by default, and which is automatically added to the list of parameters when used within a model."
      ]
    },
    {
      "metadata": {
        "id": "qd-BvdMM4KTC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's have a look at the documentation ([torch.nn.Paramter](https://pytorch.org/docs/stable/_modules/torch/nn/parameter.html))"
      ]
    },
    {
      "metadata": {
        "id": "KYE5ktka4KTC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(torch.nn.Parameter.__doc__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upgnENVo4KTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "8ed6106a-6946-43e5-f678-d992bc4a92bf"
      },
      "cell_type": "code",
      "source": [
        "mod = nn.Conv1d(10, 2, 3)\n",
        "print(mod.weight)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[[ 0.0924,  0.0328, -0.1005],\n",
            "         [-0.0339, -0.0312, -0.0266],\n",
            "         [ 0.0562, -0.1205, -0.1652],\n",
            "         [-0.0178, -0.0233,  0.1687],\n",
            "         [-0.1185, -0.1457,  0.1599],\n",
            "         [-0.1652, -0.1771,  0.1152],\n",
            "         [-0.0165,  0.1109,  0.0133],\n",
            "         [ 0.1574, -0.1611,  0.0971],\n",
            "         [ 0.0605,  0.1632, -0.0926],\n",
            "         [-0.0165,  0.1370,  0.0801]],\n",
            "\n",
            "        [[ 0.1369,  0.1705,  0.0673],\n",
            "         [ 0.1659, -0.0706, -0.0932],\n",
            "         [ 0.1545, -0.1621, -0.0136],\n",
            "         [ 0.1234, -0.0541, -0.0975],\n",
            "         [ 0.0446, -0.0070,  0.1597],\n",
            "         [ 0.1148,  0.0827, -0.1733],\n",
            "         [ 0.0719, -0.0418,  0.0889],\n",
            "         [-0.1656,  0.1242,  0.1478],\n",
            "         [-0.1533, -0.0688,  0.0158],\n",
            "         [-0.1719, -0.0966, -0.0085]]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pTCQ21544KTG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "___"
      ]
    },
    {
      "metadata": {
        "id": "TuwCQgoL4KTH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Very simple example of a module"
      ]
    },
    {
      "metadata": {
        "id": "4B2OdIzK4KTI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A module has to implemented the `forward` function which is executed during the forward pass.\n",
        "\n",
        "All your model's submodules and parameters should be instantiated in the `__init__` function. This way PyTorch know that they exist and registers them."
      ]
    },
    {
      "metadata": {
        "id": "iCgnJXNF4KTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A simple module\n",
        "class MySuperSimpleModule(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(MySuperSimpleModule, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XZbfRsJP4KTK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can use the print function to list a model's submodules/parameters:"
      ]
    },
    {
      "metadata": {
        "id": "piBIJgJh4KTL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MySuperSimpleModule(input_size=20, num_classes=5)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNIXRJGI4KTM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can use **`model.parameters()`** to get the list of parameters of your model automatically inferred by PyTorch."
      ]
    },
    {
      "metadata": {
        "id": "y4PJERT64KTN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for name, p in model.named_parameters():  # Here we use a sligtly different version of the parameters() function\n",
        "    print(name, \":\\n\", p)                 # which also returns the parameter name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B9POo8Mc4KTO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "___"
      ]
    },
    {
      "metadata": {
        "id": "GkU8QQDL4KTP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple network for image classification"
      ]
    },
    {
      "metadata": {
        "id": "pIv-hEnj4KTP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![We need to go depper](https://github.com/terezaif/amld-pytorch-workshop/blob/master/figures/deeper.jpeg?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "NeD572Dt4KTQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Your turn!"
      ]
    },
    {
      "metadata": {
        "id": "yvfkV4YQ4KTQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's create a more complicated model."
      ]
    },
    {
      "metadata": {
        "id": "IGjSFY1r4KTR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Implement a simple multilayer perceptron with two hidden layers and the following structure:"
      ]
    },
    {
      "metadata": {
        "id": "NMQ_iT-F4KTR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![](https://raw.githubusercontent.com/ledell/sldm4-h2o/master/mlp_network.png)"
      ]
    },
    {
      "metadata": {
        "id": "mr1BdTB24KTR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Input-size: *input_size*\n",
        "- 1st hidden layer: 75\n",
        "- 2nd hidden layer: 50\n",
        "- Output layer: *num_classes*\n",
        "\n",
        "Additionally, we use `ReLU`s as activation functions."
      ]
    },
    {
      "metadata": {
        "id": "oFJQL5tt4KTS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You will need some PyTorch NN modules - Find them in the [PyTorch doc](https://pytorch.org/docs/master/nn.html) (especially nn.Linear)!"
      ]
    },
    {
      "metadata": {
        "id": "RSSwUpmM4KTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F  # provides some helper functions like Relu's, Sigmoids, Tanh, etc.\n",
        "\n",
        "\n",
        "class MyMultilayerPerceptron(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(MyMultilayerPerceptron, self).__init__()\n",
        "        \n",
        "        self.input_size = input_size\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        self.linear_1 = nn.Linear(input_size, 75)\n",
        "        self.linear_2 = nn.Linear(75, 50)\n",
        "        self.linear_3 = nn.Linear(50, num_classes)\n",
        "        \n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.linear_1(x))\n",
        "        out = F.relu(self.linear_2(out))\n",
        "        out = self.linear_3(out) # because of the output it expects..\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQ5ETT9_4KTU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Print your network's parameters"
      ]
    },
    {
      "metadata": {
        "id": "khTGDou74KTV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = MyMultilayerPerceptron(784, 10)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gSr9wG_L4KTW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feed an input to your network"
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "Nl41bvrA4KTX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = torch.rand(16, 784)  # the first dimension is reserved for the 'batch_size'\n",
        "out = model(x)  # equivalent to model.forward(x)\n",
        "out[0, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mf93xaRH4KTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "___"
      ]
    },
    {
      "metadata": {
        "id": "tcU_XG5n4KTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a model"
      ]
    },
    {
      "metadata": {
        "id": "qMO_oR1n4KTZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Most of the functions to train a model follow a similar pattern in PyTorch.\n",
        "In most of the cases in consists of the following steps:\n",
        "- Loop over data (in batches)\n",
        "- Forward pass\n",
        "- Zero gradients!\n",
        "- Backward pass\n",
        "- Parameter update (Optimizer)"
      ]
    },
    {
      "metadata": {
        "id": "xuG_caKK4KTZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model, num_epochs, data_loader, device):\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Define the Loss function and Optimizer that you want to use\n",
        "    criterion = nn.CrossEntropyLoss()  \n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # NOTE: model.parameters()\n",
        "    \n",
        "    # Outter training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        # Inner training loop\n",
        "        cum_loss = 0\n",
        "        for (inputs, labels) in data_loader:\n",
        "            # Prepare inputs and labels for processing by the model (e.g. reshape, move to device, ...)\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # original shape is [batch_size, 28, 28] because it's an image of size 28x28\n",
        "            inputs = inputs.view(-1, 28*28)\n",
        "\n",
        "            # Do Forward -> Loss Computation -> Backward -> Optimization\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            cum_loss += loss.item()\n",
        "        print(\"Epoch %d, Loss=%.4f\" % (epoch+1, cum_loss/len(train_loader)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S660-PKx4KTa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note:\n",
        "- we can use the `.to` function on the model directly. Indeed, since PyTorch knows all the model parameters, it can put all the parameters on the correct device.\n",
        "- we use `model.parameters()` to get all the parameters of the model and we can instantiate an optimizer that will optimize these parameters `torch.optim.SGD(model.parameters())`.\n",
        "- to apply the forward function of the module, we write `model(input)`. In most cases, `model.forward(inputs)` would also work, but there is a slight difference : PyTorch allows you to register hook functions for a model that are automatically called when you do a forward pass on your model. Using `model(input)` will call these hooks and then call the forward function, while using `model.forward(inputs)` will just silently ignore them.\n",
        "\n",
        "Do you feel the power of Modules ?"
      ]
    },
    {
      "metadata": {
        "id": "eUPIoXFE4KTb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss functions"
      ]
    },
    {
      "metadata": {
        "id": "yAA0nnk74KTc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "PyTorch comes with a lot of predefined loss functions :\n",
        "- L1Loss\n",
        "- MSELoss\n",
        "- CrossEntropyLoss\n",
        "- NLLLoss\n",
        "- PoissonNLLLoss\n",
        "- KLDivLoss\n",
        "- BCELoss\n",
        "- MarginRankingLoss\n",
        "- HingeEmbeddingLoss\n",
        "- MultiLabelMarginLoss\n",
        "- CosineEmbeddingLoss\n",
        "- TripletMarginLoss\n",
        "- ...\n",
        "\n",
        "Check out the [PyTorch Documentation](https://pytorch.org/docs/master/nn.html#loss-functions)."
      ]
    },
    {
      "metadata": {
        "id": "c0X9-bK44KTc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "___"
      ]
    },
    {
      "metadata": {
        "id": "YpfhzkpG4KTc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's train our model on the MNIST digit classification task\n"
      ]
    },
    {
      "metadata": {
        "id": "iHhXzqxu4KTd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![MNIST](https://github.com/terezaif/amld-pytorch-workshop/blob/master/figures/mnist.jpeg?raw=1)"
      ]
    },
    {
      "metadata": {
        "id": "b0qQ9wkG4KTd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, we have to load the training and test images. MNIST is a widely used dataset, therefore the torchvision package provides simple functionalities to load images from it."
      ]
    },
    {
      "metadata": {
        "id": "5xzzVb8t4KTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "44218bce-ae6d-4402-98ca-621d9b60b95b"
      },
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# MNIST Dataset (Images and Labels)\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Dataset Loader (Input Batcher)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lSx5bduc4KTf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Call the actual training function"
      ]
    },
    {
      "metadata": {
        "id": "AmybT9dM4KTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "4d45a008-3f4b-4de3-dd9e-c7ac1543cf8e"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MyMultilayerPerceptron(input_size=784, num_classes=10)\n",
        "num_epochs = 5\n",
        "\n",
        "train(model, num_epochs, train_loader, device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss=0.3763\n",
            "Epoch 2, Loss=0.1661\n",
            "Epoch 3, Loss=0.1195\n",
            "Epoch 4, Loss=0.0937\n",
            "Epoch 5, Loss=0.0767\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nb3nNWxk4KTg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### How can we now assess the model's performance?"
      ]
    },
    {
      "metadata": {
        "id": "aMIgRzUl4KTh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This function loops over another `data_loader` (usually containing test/validation data) and computes the model's accuracy on it."
      ]
    },
    {
      "metadata": {
        "id": "4-xwWKc64KTh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(model, data_loader, device):\n",
        "    with torch.no_grad(): # during model evaluation, we don't need the autograd mechanism (speeds things up)\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in data_loader:\n",
        "            inputs = inputs.to(device)     \n",
        "            inputs = inputs.view(-1, 28*28)\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "            \n",
        "            correct += (predicted.cpu() == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            \n",
        "    acc = correct / total\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0NEcZ9R04KTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "5adebe68-9e59-4a6d-dd38-1d4e1b1ef3c8"
      },
      "cell_type": "code",
      "source": [
        "accuracy(model, test_loader, device)  # look at: accuracy(model, train_loader, device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "pFkjZqW64KTj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We get an accuracy of ~97.9%, can we do better?"
      ]
    },
    {
      "metadata": {
        "id": "ToZeimBk4KTj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "____"
      ]
    },
    {
      "metadata": {
        "id": "gj4P_26d4KTk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## How can we now store our trained model?"
      ]
    },
    {
      "metadata": {
        "id": "GAAmXVW44KTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "b2dee985-1bf3-4ead-8669-5efc3dd40902"
      },
      "cell_type": "code",
      "source": [
        "torch.save(model, \"my_model.pt\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type MyMultilayerPerceptron. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "w7C4EkSY4KTl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "my_model_loaded = torch.load(\"my_model.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J46QeVBb4KTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "8006fca0-f9aa-4b82-ba59-f127c4aae6e9"
      },
      "cell_type": "code",
      "source": [
        "model.linear_3.bias, my_model_loaded.linear_3.bias"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([-0.1698,  0.1200,  0.0855, -0.1010,  0.0383,  0.1774, -0.1378, -0.1402,\n",
              "          0.0647, -0.1008], requires_grad=True), Parameter containing:\n",
              " tensor([-0.1698,  0.1200,  0.0855, -0.1010,  0.0383,  0.1774, -0.1378, -0.1402,\n",
              "          0.0647, -0.1008], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "fHYapFjn4KTn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "____"
      ]
    },
    {
      "metadata": {
        "id": "1KRxqcsk4KTn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Don't forget to download the notebook, otherwise your changes may be lost!"
      ]
    },
    {
      "metadata": {
        "id": "bJpfbu454KTn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Download the notebook](https://github.com/terezaif/amld-pytorch-workshop/blob/master/figures/notebook-download.png?raw=1)"
      ]
    }
  ]
}